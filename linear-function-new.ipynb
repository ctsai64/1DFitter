{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T16:55:10.350860Z","iopub.status.busy":"2024-07-16T16:55:10.350329Z","iopub.status.idle":"2024-07-16T16:55:10.356323Z","shell.execute_reply":"2024-07-16T16:55:10.355427Z","shell.execute_reply.started":"2024-07-16T16:55:10.350831Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from torch.optim.lr_scheduler import StepLR"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Set device to GPU index 4\n","device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T16:59:22.282644Z","iopub.status.busy":"2024-07-16T16:59:22.282186Z","iopub.status.idle":"2024-07-16T16:59:22.304028Z","shell.execute_reply":"2024-07-16T16:59:22.303160Z","shell.execute_reply.started":"2024-07-16T16:59:22.282614Z"},"trusted":true},"outputs":[],"source":["class Multiscale1DFitter(nn.Module):\n","\n","    def __init__(self, function, x_data, input_channels, num_params, scaler=None,\n","                 post_processing=None, device=\"cuda\", loops_scaler=None, **kwargs):\n","        self.input_channels = input_channels\n","        self.scaler = scaler\n","        self.function = function\n","        self.x_data = x_data\n","        self.post_processing = post_processing\n","        self.device = device\n","        self.num_params = num_params\n","        self.loops_scaler = loops_scaler\n","\n","        super().__init__()\n","\n","        # Input block of 1d convolution\n","        self.hidden_x1 = nn.Sequential(\n","            nn.Conv1d(in_channels=self.input_channels, out_channels=8, kernel_size=7),\n","            nn.SELU(),\n","            nn.Conv1d(in_channels=8, out_channels=6, kernel_size=7),\n","            nn.SELU(),\n","            nn.Conv1d(in_channels=6, out_channels=4, kernel_size=5),\n","            nn.SELU(),\n","            nn.AdaptiveAvgPool1d(64)\n","        )\n","\n","        # Fully connected block\n","        self.hidden_xfc = nn.Sequential(\n","            nn.Linear(256, 64),\n","            nn.SELU(),\n","            nn.Linear(64, 32),\n","            nn.SELU(),\n","            nn.Linear(32, 20),\n","            nn.SELU(),\n","        )\n","\n","        # 2nd block of 1d-conv layers\n","        self.hidden_x2 = nn.Sequential(\n","            nn.MaxPool1d(kernel_size=2),\n","            nn.Conv1d(in_channels=2, out_channels=4, kernel_size=5),\n","            nn.SELU(),\n","            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n","            nn.SELU(),\n","            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n","            nn.SELU(),\n","            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n","            nn.SELU(),\n","            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n","            nn.SELU(),\n","            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n","            nn.SELU(),\n","            nn.AdaptiveAvgPool1d(16),\n","            nn.Conv1d(in_channels=4, out_channels=2, kernel_size=3),\n","            nn.SELU(),\n","            nn.AdaptiveAvgPool1d(8),\n","            nn.Conv1d(in_channels=2, out_channels=2, kernel_size=3),\n","            nn.SELU(),\n","            nn.AdaptiveAvgPool1d(4),\n","        )\n","\n","        # Flatten layer\n","        self.flatten_layer = nn.Flatten()\n","\n","        # Final embedding block\n","        self.hidden_embedding = nn.Sequential(\n","            nn.Linear(28, 16),\n","            nn.SELU(),\n","            nn.Linear(16, 8),\n","            nn.SELU(),\n","            nn.Linear(8, self.num_params),\n","        )\n","\n","    def forward(self, x, n=-1):\n","        x = torch.swapaxes(x, 1, 2)  # Swap axes 1 and 2\n","        x = self.hidden_x1(x)\n","        xfc = torch.reshape(x, (n, 256))\n","        xfc = self.hidden_xfc(xfc)\n","\n","        x = torch.reshape(x, (n, 2, 128))\n","        x = self.hidden_x2(x)\n","        cnn_flat = self.flatten_layer(x)\n","\n","        encoded = torch.cat((cnn_flat, xfc), 1)\n","        embedding = self.hidden_embedding(encoded)\n","        unscaled_param = embedding\n","\n","        if self.scaler is not None:\n","            unscaled_param = (embedding * torch.tensor(self.scaler.var_ ** 0.5).to(self.device)\n","                              + torch.tensor(self.scaler.mean_).to(self.device))\n","        else:\n","            unscaled_param = embedding\n","\n","        fits = self.function(unscaled_param, self.x_data, device=self.device)\n","        out = fits\n","\n","        if self.post_processing is not None:\n","            out = self.post_processing.compute(fits)\n","        else:\n","            out = fits\n","\n","        if self.loops_scaler is not None:\n","            out_scaled = (out - torch.tensor(self.loops_scaler.mean).to(self.device)) / torch.tensor(self.loops_scaler.std).to(self.device)\n","        else:\n","            out_scaled = out\n","\n","        return out_scaled, unscaled_param"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T16:17:27.039707Z","iopub.status.busy":"2024-07-16T16:17:27.038865Z","iopub.status.idle":"2024-07-16T16:17:27.049216Z","shell.execute_reply":"2024-07-16T16:17:27.048028Z","shell.execute_reply.started":"2024-07-16T16:17:27.039670Z"},"trusted":true},"outputs":[],"source":["'''\n","def fit_with_batch_y_data(model, optimizer, loss_func, x_data, y_data, num_epochs=100, batch_size=32):\n","    model.train()\n","    num_samples = x_data.size(0)\n","    # y_data = y_data/100\n","\n","    for epoch in range(num_epochs):\n","        epoch_loss = 0.0\n","\n","        for i in range(0, num_samples, batch_size):\n","            x_batch = x_data[i:i+batch_size]\n","            y_batch = y_data[i:i+batch_size]\n","\n","            optimizer.zero_grad()\n","            outputs, _ = model(y_batch, n=len(y_batch))\n","\n","            loss = loss_func(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += loss.item() * len(y_batch)\n","\n","        epoch_loss /= num_samples\n","\n","        if (epoch + 1) % 10 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n","'''"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["def fit_with_batch_x_data(model, optimizer, loss_func, x_data, y_data, num_epochs=100, batch_size=32):\n","    model.train()\n","    num_samples = x_data.size(0)\n","\n","    for epoch in range(num_epochs):\n","        epoch_loss = 0.0\n","\n","        for i in range(0, num_samples, batch_size):\n","            x_batch = x_data[i:i+batch_size]\n","            y_batch = y_data[i:i+batch_size]\n","            optimizer.zero_grad()\n","            outputs, _ = model(x_batch)\n","            loss = loss_func(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += loss.item() * len(x_batch)\n","\n","        epoch_loss /= num_samples\n","\n","        if (epoch + 1) % 10 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def linear_function(params, x, device='cuda'):\n","    slope = params[0] #params[:, 0].type(torch.float)#.unsqueeze(1)\n","    intercept = params[1] #params[:, 1].type(torch.float)#.unsqueeze(1)\n","    y = slope * x + intercept\n","    return y"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([  2,   6,   9, 181,  30])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["linear_function(torch.tensor([[1,2,3,4,5],[1,2,3,45,5]]), torch.tensor([1,2,2,34, 5]))"]},{"cell_type":"code","execution_count":158,"metadata":{},"outputs":[],"source":["def generate_linear_data(number_of_curves = 32, num_samples=100, x_range=10, m_range=10, b_range=10, noise_std=1.0):\n","    slopes = torch.tensor(np.random.uniform(-m_range, m_range, number_of_curves))\n","    intercepts = torch.tensor(np.random.uniform(-b_range, b_range, number_of_curves))\n","    x_data = np.random.uniform(-x_range, x_range, num_samples)    \n","    y_data = slopes.unsqueeze(-1) * x_data + intercepts.unsqueeze(-1)\n","    #linear_function(torch.stack((slopes,intercepts)), x_data) + np.random.normal(noise_std, num_samples)\n","    print(y_data.shape)\n","    \n","    x_data = torch.tensor(x_data, dtype=torch.float32).unsqueeze(1)\n","    y_data = torch.tensor(y_data, dtype=torch.float32).unsqueeze(1)\n","    \n","    return x_data, y_data, slopes, intercepts"]},{"cell_type":"code","execution_count":159,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 100])\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_3006795/1135501554.py:5: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n","  y_data = slopes.unsqueeze(-1) * x_data + intercepts.unsqueeze(-1)\n","/tmp/ipykernel_3006795/1135501554.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_data = torch.tensor(y_data, dtype=torch.float32).unsqueeze(1)\n"]}],"source":["x_data, y_data, slopes, intercepts = generate_linear_data()\n"]},{"cell_type":"code","execution_count":160,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([32, 1, 100])"]},"execution_count":160,"metadata":{},"output_type":"execute_result"}],"source":["y_data.shape"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[],"source":["def generate_batch_data(batch_size=32, num_samples=100, x_range=10, m_range=10, b_range=10, noise_std=1.0):\n","    batch_x = []\n","    batch_y = []\n","    slopes_t = []\n","    intercepts_t = []\n","\n","    \n","    for _ in range(batch_size):\n","        slopes = torch.tensor(np.random.uniform(-m_range, m_range, num_samples))\n","        intercepts = torch.tensor(np.random.uniform(-b_range, b_range, num_samples))\n","        x = np.random.uniform(-x_range, x_range, num_samples)\n","        y = linear_function(torch.stack((slopes,intercepts)), x)#slopes*x + intercepts + torch.rand(num_samples)*noise_std #linear_function(torch.stack((slopes,intercepts)), x_data)\n","        \n","        x = torch.tensor(x, dtype=torch.float32).unsqueeze(1)\n","        y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n","        batch_x.append(x)\n","        batch_y.append(y)\n","        slopes_t.append(slopes)\n","        intercepts_t.append(intercepts)\n","    \n","    batch_x = torch.stack(batch_x)\n","    batch_y = torch.stack(batch_y)\n","    \n","    return batch_x, batch_y, slopes_t, intercepts_t"]},{"cell_type":"code","execution_count":116,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T16:55:36.515149Z","iopub.status.busy":"2024-07-16T16:55:36.514750Z","iopub.status.idle":"2024-07-16T16:55:36.559323Z","shell.execute_reply":"2024-07-16T16:55:36.558482Z","shell.execute_reply.started":"2024-07-16T16:55:36.515117Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_3006795/2347689592.py:4: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n","  y = slope * x + intercept\n","/tmp/ipykernel_3006795/858176006.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n"]},{"data":{"text/plain":["(torch.Size([32, 100, 1]), torch.Size([32, 100, 1]))"]},"execution_count":116,"metadata":{},"output_type":"execute_result"}],"source":["x_data, y_data, m, b = generate_batch_data()\n","x_data.shape, y_data.shape"]},{"cell_type":"code","execution_count":168,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_3006795/1949054914.py:6: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n","  y_line = slope * x_line + intercept\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["x_data_np = x_data.numpy()\n","y_data_np = y_data.numpy()\n","for i in range(32):\n","    for slope, intercept in zip(m[i], b[i]):\n","        x_line = np.linspace(np.min(x_data_np[i]), np.max(x_data_np[i]), 100)\n","        y_line = slope * x_line + intercept\n","        plt.plot(x_line, y_line)#, label=f'Batch {i+1}')\n","\n","plt.title('Generated Data')\n","plt.xlabel('X')\n","plt.ylabel('Y')\n","#plt.legend()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[{"data":{"text/plain":["(torch.Size([32, 100, 1]), torch.Size([100, 1]))"]},"execution_count":125,"metadata":{},"output_type":"execute_result"}],"source":["x_data.shape, y_data.shape"]},{"cell_type":"code","execution_count":133,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T16:57:57.410841Z","iopub.status.busy":"2024-07-16T16:57:57.410444Z","iopub.status.idle":"2024-07-16T16:57:57.421067Z","shell.execute_reply":"2024-07-16T16:57:57.420293Z","shell.execute_reply.started":"2024-07-16T16:57:57.410813Z"},"trusted":true},"outputs":[],"source":["model = Multiscale1DFitter(function=linear_function, x_data=x_data, input_channels=1, num_params=2)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n","loss_func = nn.MSELoss()"]},{"cell_type":"code","execution_count":148,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([100, 1])"]},"execution_count":148,"metadata":{},"output_type":"execute_result"}],"source":["y_data.shape"]},{"cell_type":"code","execution_count":166,"metadata":{},"outputs":[],"source":["dataset = TensorDataset(y_data.swapaxes(1,2))\n","dataloader = DataLoader(dataset, 32)"]},{"cell_type":"code","execution_count":167,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 100, 1])\n"]},{"name":"stderr","output_type":"stream","text":["/home/cymberly/miniconda3/envs/fitter/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 100, 1])) that is different to the input size (torch.Size([32, 100, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"name":"stdout","output_type":"stream","text":["torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","Epoch [10/100], Loss: 360.2294\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","Epoch [20/100], Loss: 360.0947\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n","torch.Size([32, 100, 1])\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[167], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m outputs, _ \u001b[38;5;241m=\u001b[39m model(y)\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(outputs, y)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)\n","File \u001b[0;32m~/miniconda3/envs/fitter/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/fitter/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/fitter/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model.train()\n","num_samples = x_data.size(0)\n","for epoch in range(100):\n","    epoch_loss = 0.0\n","    for batch in dataloader:\n","        y = batch[0]\n","        print(y.shape)\n","        optimizer.zero_grad()\n","        outputs, _ = model(y)\n","        loss = loss_func(outputs, y)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item() * len(y)\n","    epoch_loss /= num_samples\n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch [{epoch+1}/{100}], Loss: {epoch_loss:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T16:59:29.802132Z","iopub.status.busy":"2024-07-16T16:59:29.801241Z","iopub.status.idle":"2024-07-16T16:59:30.013705Z","shell.execute_reply":"2024-07-16T16:59:30.012305Z","shell.execute_reply.started":"2024-07-16T16:59:29.802099Z"},"trusted":true},"outputs":[],"source":["#fit_with_batch_y_data(model, optimizer, loss_func, x_data, y_data)"]},{"cell_type":"code","execution_count":135,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/cymberly/miniconda3/envs/fitter/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 100, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"ename":"RuntimeError","evalue":"The size of tensor a (100) must match the size of tensor b (32) at non-singleton dimension 1","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[135], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfit_with_batch_x_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[39], line 13\u001b[0m, in \u001b[0;36mfit_with_batch_x_data\u001b[0;34m(model, optimizer, loss_func, x_data, y_data, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     12\u001b[0m outputs, _ \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[0;32m---> 13\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m~/miniconda3/envs/fitter/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/fitter/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/fitter/lib/python3.11/site-packages/torch/nn/modules/loss.py:535\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/fitter/lib/python3.11/site-packages/torch/nn/functional.py:3365\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3363\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3365\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n","File \u001b[0;32m~/miniconda3/envs/fitter/lib/python3.11/site-packages/torch/functional.py:76\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (32) at non-singleton dimension 1"]}],"source":["fit_with_batch_x_data(model, optimizer, loss_func, x_data, y_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T16:21:12.296884Z","iopub.status.busy":"2024-07-16T16:21:12.296423Z","iopub.status.idle":"2024-07-16T16:21:12.305525Z","shell.execute_reply":"2024-07-16T16:21:12.304105Z","shell.execute_reply.started":"2024-07-16T16:21:12.296847Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, loss_func, x_data, y_data, device='cuda'):\n","    model.eval()\n","    x_data = x_data.to(device)\n","    y_data = y_data.to(device)\n","    with torch.no_grad():\n","        outputs, _ = model(x_data, n=len(x_data))\n","        loss = loss_func(outputs, y_data)\n","        print(f'Validation Loss: {loss:.4f}')        "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T16:20:30.949924Z","iopub.status.busy":"2024-07-16T16:20:30.948580Z","iopub.status.idle":"2024-07-16T16:20:30.955435Z","shell.execute_reply":"2024-07-16T16:20:30.954309Z","shell.execute_reply.started":"2024-07-16T16:20:30.949879Z"},"trusted":true},"outputs":[],"source":["x_val, y_val, _, _ = generate_linear_data()\n","x_val = x_val.view(1, 1, -1)\n","evaluate(model, loss_func,x_val, y_val)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class LinearModel(nn.Module):\n","    def __init__(self):\n","        super(LinearModel, self).__init__()\n","        self.fc1 = nn.Linear(1, 10)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(10, 10)\n","        self.fc3 = nn.Linear(10, 1)\n","    \n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.relu(x)\n","        x = self.fc3(x)\n","        return x\n","\n","class ConvModel(nn.Module):\n","    def __init__(self):\n","        super(ConvModel, self).__init__()\n","        self.conv1 = nn.Conv1d(1, 10, kernel_size=3, padding=1)\n","        self.relu = nn.ReLU()\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(10, 1) \n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def fit_batch_sched(model, optimizer, loss_func, scheduler, x_data, y_data, num_epochs=100, batch_size=32):\n","    model.train()\n","    num_samples = x_data.size(0)\n","\n","    for epoch in range(num_epochs):\n","        epoch_loss = 0.0\n","\n","        for i in range(0, num_samples, batch_size):\n","            x_batch = x_data[i:i+batch_size]\n","            y_batch = y_data[i:i+batch_size]\n","\n","            optimizer.zero_grad()\n","            outputs, _ = model(x_batch, n=len(x_batch))\n","\n","            loss = loss_func(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","            epoch_loss += loss.item() * len(x_batch)\n","\n","        epoch_loss /= num_samples\n","\n","        if (epoch + 1) % 10 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n","\n","def fit(model, optimizer, loss_func, scheduler, x_data, y_data, num_epochs=100):\n","    for epoch in range(num_epochs):\n","        out_scaled, unscaled_param = model(x_data)\n","        loss = loss_func(out_scaled, y_data)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        if (epoch+1) % 10 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# scheduler = StepLR(optimizer, step_size=100, gamma=0.1)\n","# fit_batch_sched(model, optimizer, loss_func, scheduler, x_data, y_data)\n","# scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n","# fit(model, optimizer, loss_func, scheduler, x_data, y_data)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
